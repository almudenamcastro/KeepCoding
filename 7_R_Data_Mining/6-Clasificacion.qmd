---
title: "Regresión logística"
format: html
editor: visual
  markdown: 
    wrap: 72
---

# Regresión logística

Tenemos dos grupos de datos, de dos tipos diferentes, tipo 1 y tipo 2. Los tipos tienen características diferentes (los parámetros que los caracterizan pueden tomar distintos valores).

```{r}
library(tidyverse)

set.seed(5)
ejemplo <- data.frame(tipo = c(rep(0,10), rep(1,15)), 
                      param = c(rnorm(10, 5, 2), rnorm(5, 17, 6), rnorm(10,32,7)))

grafico <- ejemplo |>
  ggplot(aes(x=param, y=tipo)) +
  geom_point(aes(color=factor(tipo))) +
  theme_bw()

grafico
```

En lugar de predecir su valor, lo que queremos es hacer un clasificador, una función que nos permita separarlos. Para ello, tenemos que realizar ciertas modificaciones a la regresión lineal.

La fórmula de la regresión lineal es:

$$ 
\hat{Y}=\beta\_1 X_1+\beta\_2 X_2+\cdots +\beta\_p X_p = \sum \beta\_k X_k 
$$

```{r}
modelo_lm <- lm(as.numeric(tipo)~param, data=ejemplo)
bm <- modelo_lm$coefficients
umbral <- (0.5-bm[1])/bm[2]

grafico2 <- grafico +  
  geom_abline(intercept=bm[1], slope= bm[2], color="grey") +
  geom_rect(xmin=umbral, xmax=Inf, ymin=-Inf, ymax=Inf, alpha=0.01) 

grafico2

```

El problema es que esta regresión puede tomar cualquier valor, pero lo que intentamos predecir son probabilidades, valores lógicos que van entre 0 y 1. De hecho, usar un modelo lineal no es del todo correcto porque los datos **NO** siguen una distribución gaussiana. Siguen una distribución **binomial** con dos posibles valores 0 o 1.

### Distribución binomial:

La distribución binomial es una generalización de la distribución de Bernoulli para $n$ sucesos independientes, cada uno de los cuales tiene dos posibles resultados Si/No con probabilidad $p$. (por ejemplo: tiramos al aire 3 monedas y mirarmos cual es la probabilidad de que 2 salgan cara).

Variables que definen la distribución:

-   p: probabilidad de éxito de un caso individual
-   n: número de eventos totales que se desean medir
-   k: número de eventos que ha salido SI.

Estimadores: -

-   **media**:

$$ 
\mu = n· p
$$

-   **varianza**:

$$
\sigma^2=n·p·(1-p)
$$

Si tenemos $n$ sucesos independientes que siguen una distribución de Bernoulli, ¿cual es la probabilidad de que $k$ sucesos sean positivos? Si sabemos que la probabilidad de un suceso ($k=1$) que sigue una distribución Bernoulli viene dada por la función de distribución:

$$
Pr_{Bernoulli}(X=k) = p^k (1-p) ^{n-k} \qquad k \in \left\{0, 1 \right\}
$$

Al tener $k$ sucesos donde $k \in \left\{0,1,2,...,n \right\}$, la función será la de Bernoulli multiplicada por el coeficiente binomial:

$$ 
Pr(X=k)=\binom{n}{k}p^k(1-p)^{n-k} \qquad \binom{n}{k}=\frac{n!}{k!(n-k)!}
$$

La función acumulativa será:

$$ Pr(X \leq k)= \sum_{i=0}^{k-1} \binom{n}{k}p^k(1-p)^{n-k} $$

### Función de enlace (link function)

Para pasar del dominio de números reales $(-\infty,\infty)$ al de probabilidades $[0,1]$ a vamos a utilizar la **función logística**:

$$ p = h(x)= \frac{1}{1+e^{-x}} $$

```{r}
# Pintamos la función logística: 
x <- seq(-10,10,length.out = 100)
y <- 1/(1+exp(-x))
plot(x,y,t="l")

```

Su inversa se conoce como la función **logit**:

$$ 
h^{-1}(p) = ln \left( \frac{p}{1-p} \right) 
$$

```{r}
# Pintamos la función logit: 
x <- seq(0,1,length.out = 100)
y <- log(x/(1-x))
plot(x,y,t="l")
```

Cuando estemos trabajando con una **distribución binomial** un modelo lineal del tipo:

$$ y = \vec{\beta} \vec{x}+\beta_0 $$

será:

$$ 
y = p(x) = \frac{1}{1+e^{-\vec{\beta} \vec{x}-\beta_0}} 
$$

**Nota:** Por ejemplo, si usamos solo un parámetro como entrada, con los coeficientes $\beta_0$ y $\beta_1$ estaríamos aplicamos una transformación lineal sobre la x y luego introduciéndola como parámetro de la función logística. Sería como estirar y desplazar lateralmente la función.

Ahora $p(x)$ es una función que devuelve valores en el rango $[0,1]$, puede ser considerada como una probabilidad. Y podemos usarla como clasificador:

-   si p(x)\>=0.5 seleccionamos clase 1
-   si p(x)\< 0.5 seleccionamos clase 0

Es decir, tenemos una probabilidad, su valor está en el rango $[0,1]$:

$$ p = \frac{1}{1-e^{-\hat{Y}}}= \frac{1}{1-e^{-(\beta_1 X_1+\beta_2 X_2+\cdots +\beta_p X_p)}}$$

### Razón de monomios: 

Definimos la razón de monomios (Odds ratio) como el cociente entre dos probabilidades, su valor está en el rango $[0,\infty]$:

$$ Odds=\frac{p(\vec{x})}{1-p(\vec{x})} = \frac{\frac{1}{1+e^{-\beta \vec{x}-\beta_0}}}{1-\frac{1}{1+e^{-\beta \vec{x}-\beta_0}} } = \frac{1}{1+e^{-\vec{\beta} \vec{x}-\beta_0}-1} $$

Simplificando:

$$ Odds= e^{\vec{\beta} \vec{x}+\beta_0} =e^{(\beta_1 X_1+\beta_2 X_2+\cdots +\beta_p X_p)} $$

Si aplicamos el logaritmo a la razón de monomios, volvemos a obtener la función logit, cuyo valor está comprendido entre $[-\infty,\infty]$:

$$ ln(Odds)= ln \left(\frac{p}{1-p} \right) = \beta_1 X_1+\beta_2 X_2+\cdots +\beta_p X_p $$

### Optimización de la función de coste:

La **función de coste** es una función que nos permite calcular la diferencia entre los valores predichos por un modelo y los datos que tenemos. De manera general, se podría expresar como:

$$
Cost(p(x),y) = L(\beta)= {1 \over n} \sum_{i=0}^n{(y_i-\vec{y_i})^2} = {1 \over n} \sum_{i=0}^n{(y_i-p(\beta \vec {x_i}))^2}
$$

Donde los valores $y_i$ con los datos reales que tenemos, mientras que $p(x_i)$ son los valores predichos por el modelo. La anterior es la función que debíamos minimizar en el caso de la regresión lineal para obtener los coeficientes $\beta_i$.

En el caso de la regresión logística, la cosa se complica un poco. En este caso no queremos minimizar la "distancia" entre dos puntos (los datos $y_i$ y su proyección sobre la recta $p(x_i)$). Como los valores $y_i$ solo pueden valer 1 o 0, lo que queremos, en este caso, es maximizar el número total de aciertos. Esto se expresa mediante una función de coste que tiene la siguiente forma:

$$L(\beta) = \prod_i^n  p(\beta \vec{x_i})^{y_i}·(1-p(\beta \vec{x_i}))^{1-y_i}$$

Lo **bonito** de esta función de coste $L(\beta_i)$ es que siempre que acertamos (es decir siempre que tanto $y_i$ como $p(x_i)$ valen 1 o cuando ambas valen 0), el coste toma una valor de 1. Mientras que si fallamos (cuando $y_i$=1 y $p(x_i)\approx 0$ o viceversa), el coste pasa a valer 0\*.

-   **Nota**: puede resultar contraintuitivo que el coste "aumente" con los aciertos. A veces esta misma función se encuentra con los exponentes cambiados de signo (esto hace que uno de los términos tienda a $0^-1$ en caso de error). Pero ambas son equivalentes. Si $L(\beta_i)$ aumenta con los aciertos, querremos maximizarla. Si disminuye, querremos minimizarla. A gusto del consumidor.

-   **Nota 2**: Mola mucho que cada término de $L(\beta_i)$ sea, en sí mismo, una distribución de Bernoulli $p^x·(1-p)^{1-x}$... de hecho, cuando optimizamos esta función, estamos maximizando los "aciertos" en la matriz de confusión.

Como el productorio es poco manejable, podemos usar logaritmos y convertir la función de coste en:

$$ 
\ln (L(\beta)) = \frac{1}{n}\sum_i^n \ln \left( p(\beta\vec{x_i})^{y_i}·(1-p(\beta\vec{x_i}))^{1-y_i}\right) \\ 
= \frac{1}{n}\sum_i^n y_i ·\ln p(\beta\vec{x_i}) + (1-y_i)·\ln (1-p(\beta\vec{x_i})) \\
$$

Derivando esta función (con un poco de paciencia, ver https://www.youtube.com/watch?v=wB2aW7VMHOI), llegamos a:

$$
\frac {d L(\beta)}{d\beta}=\frac{1}{n}\sum _i ^n (y_i - p(\beta \vec{x_i})· \bar x
$$

### Generalized Linear Models

En R, para obtener calcular un modelo basado en este tipo de regresión logística, utilizaremos la función glm. Le pasaremos como parámetros: 


* **formula:** ej: formula = y \~ x1 + x2 +... 

* **family:** binomial(link="logit") 

* **data:** el dataframe que usemos para el entrenamiento.

**ojo**: La salida del modelo es log(odds):

$$ y = log(Odds) = \beta_1 X_1+\beta_2 X_2+\cdots +\beta_p X_p $$


```{r}
modelo_glm <- glm(tipo~param, data=ejemplo, family="binomial")
gbm <- modelo_glm$coefficients
```


Si queremos la probabilidad tenemos que aplicar un poco de cálculo e invertir, nuevamente, la función logit:

$$ Odds = \frac{p}{1-p} $$

$$ y = log(Odds) = log \left( \frac{p}{1-p} \right) \\ p=\frac{1}{1+e^{-y}} $$
```{r}
x <- seq(0,45,length.out = 500)
y <- 1/(1+exp(-(gbm[2]*x + gbm[1])))

sigmoide <- data.frame(x,y)

grafico2 + 
  geom_line(aes(x=x, y=y), data=sigmoide)
```
## Matriz de confusión

Aquí lo que tenemos es un clasificador con dos hipótesis $H_0$ (hipótesis negativa) y $H_1$ (hipótesis positiva). Si nuestro test estadístico dice que la hipótesis $H_1$ es cierta pero en realidad la que es cierta es la hipótesis $H_0$ estaremos cometiendo un error. El tipo de error depende de si nos hemos equivocado prediciendo $H_0$ o $H_1$.

| .            | Elegimos $H_0$                | Elegimos $H_1$               |
|-----------------|----------------------------|---------------------------|
| $H_0$ cierta | No hay error                  | Error tipo I, falso positivo |
| $H_1$ cierta | Error tipo II, falso negativo | No hay error                 |

La matriz de confusión lo que hace es contar el número de ocurrencias que ha habido en cada celda:

### Medidas de calidad

Imaginemos que tenemos la siguiente matriz de confusión:

| .                  | Predecimos condición negativa | Predecimos condición positiva |
|------------------|---------------------------|---------------------------|
| Condición negativa | $M_{11}$                      | $M_{12}$                      |
| Condición positiva | $M_{21}$                      | $M_{22}$                      |

-   **Precisión** : Cuántos aciertos tengo del total de predicciones. Nos habla de **calidad**.$$\frac{M_{22}{M_{12}+M_{22}}$$

-   **Exhaustividad** (recall, true positive rate): Qué ratio de los aciertos positivos soy capaz de encontrar. Nos habla de **cantidad** de encuentros.

    $$\frac{M_{22}}{M_{21}+M_{22}}$$.

-   **Exactitud** (Accuracy): Cuantas predicciones correctas he hecho.

    $$\frac{M_{11}+M_{22}}{M_{11}+M_{12}+M_{21}+M_{22}}$$

-   **Valor-F**:

    $$F_\beta=(1+\beta^2)\frac{Precisión·Exhaustividad}{\beta^2·Precisión+Exhaustividad}$$

-   **Probabilidad de falso positivo** (false positive rate):Cuántos positivos **erróneos** he detectado de todos los negativos que hay.

    $$\frac{M_{12}}{M_{12}+M_{11}}$$

A veces la matriz de confusión se muestra cambiada, de hecho Python lo hace así, intercambia las filas y las columnas. Más información aquí: https://towardsdatascience.com/the-two-variations-of-confusion-matrix-get-confused-never-again-8d4fb00df308

```{r}
fscore<-function(M,beta){
    pr=M[1,1]/(M[1,2]+M[1,1])
    rc=M[1,1]/(M[2,1]+M[1,1])
    (1+beta^2)*pr*rc/(beta^2*pr+rc)
}

paste("Precision:",M[2,2]/(M[1,2]+M[2,2]))
paste("Recall, true positive rate:",   M[2,2]/(M[2,1]+M[2,2]))
paste("False positive rate:",   M[1,2]/(M[1,2]+M[1,1]))
paste("Accuracy:", (M[1,1]+M[2,2])/(M[1,1]+M[1,2]+M[2,1]+M[2,2]))
paste("F0.5-score",fscore(M,0.5))
paste("F1-score",fscore(M,1))
paste("F2-score",fscore(M,beta=2))
```

## Curva ROC

La curva ROC fue comenzada a usar durante la segunda guerra mundial para el análisis de las señales de radar. Después del ataque de Pearl Harbor en 1941, la armada de EEUU comenzó un programa de investigación para aumentar la predicción de los radares a la hora de detectar aviones japoneses. Para ello midieron la habiliad de un radar de detectar esas señales, esa medida la llamaron "Receiver Operating Characteristic".

Se utiliza para ver la calidad de un detector, un clasificador binario capaz de detectar un elemento. Se hace un barrido por todos los umbrales y se mide el valor de positivo verdadero en función de falso positivo.

### AUC

Area bajo la curva (Area Under The Curve), número entre 0 y 1 que mide como de bueno es un clasificador.

Es el area bajo la curva ROC, cuando su valor es: \* 1 significa que el clasificador es perfecto \* 0.5 significa que la elección es tan buena como hacerla al azar \* Menor de 0.5, significa que lo estamos haciendo peor que el azar


